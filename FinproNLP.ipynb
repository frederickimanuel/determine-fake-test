{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinproNLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suf-QHTFTLZE",
        "colab_type": "text"
      },
      "source": [
        "# **Final Project NLP**\n",
        "by:\n",
        "\n",
        "*   Daniel Anando Wangean (2201812002)\n",
        "*   Finley Febianto (2201736864)\n",
        "*   Frederick Imanuel Setiawan (2201766394)\n",
        "*   Zaky Ahmad Hanif Raksakusumah (2201828322)\n",
        "\n",
        "---\n",
        "Pertama dataset diload\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQsGiJnUeOs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5uPkYz6g14Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_fake = pd.read_csv('Fake.csv')\n",
        "data_true = pd.read_csv('True.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE8wHZv6vdxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# memberi kolom tambahan untuk manandai: 0 untuk fake dan 1 untuk true\n",
        "# lalu data digabung menjadi 1 dataset\n",
        "data_fake['truth'] = 'fake'\n",
        "data_true['truth'] = 'true'\n",
        "\n",
        "dataset = pd.concat([data_fake, data_true], axis=0, ignore_index=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjWb-bDwUrPA",
        "colab_type": "text"
      },
      "source": [
        "Melakuakan Normalisasi data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJToifz5mjbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['text'] = dataset['text'].str.lower() # Menjadikan lowercase\n",
        "dataset['text'] = dataset['text'].str.replace('[!”#$%&’‘\\'()*+,-./:;<=>?@[\\]^_`{|}~]', '') # Menghilangkan Punctuation\n",
        "dataset['text'] = dataset['text'].str.strip() # Menghilangkan whitespace "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxlRa_TtVU5r",
        "colab_type": "text"
      },
      "source": [
        "Pembagian data. Fitur yang dipiliha ada text. Alasannya adalah berita dapat dinilai palsu atau tidak berdasarkan isinya.\n",
        "\n",
        "Untuk testing, digunakan 20% dari total data gabungan, diambil secara acak"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viKs8GrejvFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = dataset['text']\n",
        "y = dataset['truth']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhDVyMoYVhxs",
        "colab_type": "text"
      },
      "source": [
        "Kami pilih 5 classifier yang cocok dan dicek untuk akurasi paling tinggi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4WZHhHakQvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "bnb = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', BernoulliNB())])\n",
        "mnb = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', MultinomialNB())])\n",
        "lrc = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', LogisticRegression())])\n",
        "rfc = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', RandomForestClassifier())])\n",
        "dtc = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', DecisionTreeClassifier(criterion= 'entropy',\n",
        "                                                  max_depth = 10,\n",
        "                                                  splitter='best',\n",
        "                                                  random_state=42))])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go7yxr48KJJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bnb = bnb.fit(x_train, y_train)\n",
        "mnb = mnb.fit(x_train, y_train)\n",
        "lrc = lrc.fit(x_train, y_train)\n",
        "rfc = rfc.fit(x_train, y_train)\n",
        "dtc = dtc.fit(x_train, y_train)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lssMo1_V1G4",
        "colab_type": "text"
      },
      "source": [
        "Perhitungan evaluasi masing-masing algoritma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heob5bEBP-na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYn9vqUJOx1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "cd835926-6f0c-4714-f66c-aecdd1e06359"
      },
      "source": [
        "prediksi_bnb = bnb.predict(x_test)\n",
        "\n",
        "print(\"Evaluasi Bernoulli Naive Bayes\\n\\n\")\n",
        "print(classification_report(y_test,prediksi_bnb))\n",
        "print(\"\\n akurasi Bernoulli Naive Bayes: {}%\".format(round(accuracy_score(y_test,prediksi_bnb)*100,2)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluasi Bernoulli Naive Bayes\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.98      0.92      0.95      4733\n",
            "        true       0.92      0.98      0.95      4247\n",
            "\n",
            "    accuracy                           0.95      8980\n",
            "   macro avg       0.95      0.95      0.95      8980\n",
            "weighted avg       0.95      0.95      0.95      8980\n",
            "\n",
            "\n",
            " akurasi Bernoulli Naive Bayes: 94.99%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Mm2sVlpQWWK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e058b424-fbde-4ae6-b0fa-8a51c5d52af9"
      },
      "source": [
        "prediksi_mnb = mnb.predict(x_test)\n",
        "\n",
        "print(\"Evaluasi Multinomial Naive Bayes\\n\\n\")\n",
        "print(classification_report(y_test,prediksi_mnb))\n",
        "print(\"\\n akurasi Multinomial Naive Bayes: {}%\".format(round(accuracy_score(y_test,prediksi_mnb)*100,2)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluasi Multinomial Naive Bayes\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.95      0.95      0.95      4733\n",
            "        true       0.94      0.95      0.95      4247\n",
            "\n",
            "    accuracy                           0.95      8980\n",
            "   macro avg       0.95      0.95      0.95      8980\n",
            "weighted avg       0.95      0.95      0.95      8980\n",
            "\n",
            "\n",
            " akurasi Multinomial Naive Bayes: 94.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zvxwuhbNQXBw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "550c5a27-7cf4-49f3-85e5-33c8671ef1aa"
      },
      "source": [
        "prediksi_lrc = lrc.predict(x_test)\n",
        "\n",
        "print(\"Evaluasi Linear Regression\\n\\n\")\n",
        "print(classification_report(y_test,prediksi_lrc))\n",
        "print(\"\\n akurasi Linear Regression: {}%\".format(round(accuracy_score(y_test,prediksi_lrc)*100,2)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluasi Linear Regression\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.99      0.99      0.99      4733\n",
            "        true       0.99      0.99      0.99      4247\n",
            "\n",
            "    accuracy                           0.99      8980\n",
            "   macro avg       0.99      0.99      0.99      8980\n",
            "weighted avg       0.99      0.99      0.99      8980\n",
            "\n",
            "\n",
            " akurasi Linear Regression: 99.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NvU0eC8pQYZg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "91899bdc-b338-44bb-f96c-a55165d8db29"
      },
      "source": [
        "prediksi_rfc = rfc.predict(x_test)\n",
        "\n",
        "print(\"Evaluasi Random Forest Classifier\\n\\n\")\n",
        "print(classification_report(y_test,prediksi_rfc))\n",
        "print(\"\\n akurasi Random Forest Classifier: {}%\".format(round(accuracy_score(y_test,prediksi_rfc)*100,2)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluasi Random Forest Classifier\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.99      0.99      0.99      4733\n",
            "        true       0.99      0.99      0.99      4247\n",
            "\n",
            "    accuracy                           0.99      8980\n",
            "   macro avg       0.99      0.99      0.99      8980\n",
            "weighted avg       0.99      0.99      0.99      8980\n",
            "\n",
            "\n",
            " akurasi Random Forest Classifier: 98.93%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oB1s4vEWQYi8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e4d490f2-1e6e-4d08-af71-be06705a0977"
      },
      "source": [
        "prediksi_dtc = dtc.predict(x_test)\n",
        "\n",
        "print(\"Evaluasi Decision Tree Classifier\\n\\n\")\n",
        "print(classification_report(y_test,prediksi_dtc))\n",
        "print(\"\\n akurasi Decision Tree Classifier: {}%\".format(round(accuracy_score(y_test,prediksi_dtc)*100,2)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluasi Decision Tree Classifier\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       1.00      0.99      1.00      4733\n",
            "        true       0.99      1.00      0.99      4247\n",
            "\n",
            "    accuracy                           1.00      8980\n",
            "   macro avg       1.00      1.00      1.00      8980\n",
            "weighted avg       1.00      1.00      1.00      8980\n",
            "\n",
            "\n",
            " akurasi Decision Tree Classifier: 99.51%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2nsw9kwXlpl",
        "colab_type": "text"
      },
      "source": [
        "Didapati bahwa Decision Tree Classifier memiliki akurasi tertinggi dibanding lainnya. Untuk itu, kami mencoba memberikan sejumlah artikel berita asli (true) sebagai uji coba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R142O-GPYDA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7eef71f4-e60c-45bc-b761-063f11f17a47"
      },
      "source": [
        "testing = pd.read_csv(\"UjiCoba.csv\")\n",
        "\n",
        "testing['text'] = testing['text'].str.lower() \n",
        "testing['text'] = testing['text'].str.replace('[!”#$%&’‘\\'()*+,-./:;<=>?@[\\]^_`{|}~]', '')\n",
        "testing['text'] = testing['text'].str.strip() \n",
        "testing = testing.drop(['date'],axis=1)\n",
        "\n",
        "hasil = dtc.predict(testing['text'])\n",
        "hasil\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
              "       'fake', 'fake'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWoKaHajifj1",
        "colab_type": "text"
      },
      "source": [
        "Ternyata hasil yang didapat adalah fake semua walaupun berita tersebut diambil dari sumber yang akredibel. Kemungkinan ini dapat terjadi dikarenakan data yang digunakan untuk training adalah berita tahun 2017 sedangkan berita yang digunakan uji coba adalah 2020.\n",
        "\n",
        "Wajar jika semua berita dianggap fake karena model algoritma hanya mempelajari hal-hal yang ada di tahun 2017. Jadi, apa yang didapati di tahun 2020 dianggap salah karena banyak hal telah berubah.\n",
        "\n",
        "Jadi, dapat ditafsirkan jika metode ini bisa bekerja baik jika data yang dimiliki up to date dan berasal dari berbagai topik dan sumber."
      ]
    }
  ]
}